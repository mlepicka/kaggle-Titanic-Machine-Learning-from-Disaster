{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fschmidt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/fschmidt/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.model_selection  import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "After importing neeeded libraries, we begin with feature enginnering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(pd.read_csv('train.csv')) # insert path to csv files here\n",
    "df2 = pd.DataFrame(pd.read_csv('test.csv'))\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "\n",
    "df = [df1, df2]\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    df[i]['Sex'] = df[i]['Sex'].map({'female': 1, 'male': 0})\n",
    "    df[i]['Embarked'] = df[i]['Embarked'].map({'Q': 1, 'C': 0, 'S': 2})\n",
    "    df[i][\"Age\"] = imp.fit_transform(df[i][[\"Age\"]]).ravel()\n",
    "    df[i]['Embarked'] = imp.fit_transform(df[i][['Embarked']]).ravel()\n",
    "    df[i].Embarked = df[i].Embarked.astype(int)\n",
    "    df[i].Age = df[i].Age.astype(int)\n",
    "    df[i]['FamilySize'] = df[i]['SibSp'] + df[i]['Parch'] + 1\n",
    "    df[i] = df[i].assign(FamilySize = pd.Series(df[i]['FamilySize']))\n",
    "    df[i]['HasCabin'] = df[i]['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "#     df['Name_length'] = df['Name'].apply(len)\n",
    "#     df['IsAlone'] = 0\n",
    "#     df.loc[df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    df[i]['Single'] = df[i]['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n",
    "    df[i]['SmallF'] = df[i]['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "    df[i]['MedF'] = df[i]['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "    df[i]['LargeF'] = df[i]['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n",
    "    df[i]['Title'] = df[i]['Name'].apply(get_title)\n",
    "    df[i]['Title'] = df[i]['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df[i]['Title'] = df[i]['Title'].replace('Mlle', 'Miss')\n",
    "    df[i]['Title'] = df[i]['Title'].replace('Ms', 'Miss')\n",
    "    df[i]['Title'] = df[i]['Title'].replace('Mme', 'Mrs')\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    df[i]['Title'] = df[i]['Title'].map(title_mapping)\n",
    "    df[i]['Title'] = df[i]['Title'].fillna(0)\n",
    "\n",
    "    #df[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in df['Cabin'] ])\n",
    "    #df['Cabin'] = df['Cabin'].map({'A': 1, 'B': 1, 'C': 1, 'D': 1, 'E': 1, 'F': 1, 'G': 1, 'T': 1})\n",
    "    \n",
    "df1 = df[0]\n",
    "df2 = df[1]\n",
    "df1 = df1.drop(columns = ['PassengerId', 'Name', 'Cabin', 'Ticket', 'Fare', 'Age']) # 'Name_length',\n",
    "df2 = df2.drop(columns = ['Name', 'Cabin', 'Ticket', 'Fare',  'Age']) #'Name_length',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "We train our models:\n",
    "\n",
    "1. LightGBM\n",
    "2. XGBoost\n",
    "3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_repeated_cv(X, y):\n",
    "    #set the number of repetitions\n",
    "    n_reps = 50\n",
    "\n",
    "    for u in range(n_reps):\n",
    "        #initialize vector to keep predictions from all folds of the cross-validation\n",
    "        y_predict_lgb = np.zeros(y.shape)\n",
    "        y_predict_xgb = np.zeros(y.shape)\n",
    "        y_predict_reg = np.zeros(y.shape)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits = 5, random_state = 142)\n",
    "        for train, test in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "            y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "            #standardization\n",
    "            sc = StandardScaler().fit(X_train)\n",
    "            X_train = sc.transform(X_train)\n",
    "            X_test = sc.transform(X_test)\n",
    "            \n",
    "        #============================================================================\n",
    "        # LGBM    \n",
    "        \n",
    "            d_train = lgb.Dataset(X_train, label = y_train)\n",
    "            \n",
    "            params = {'boosting_type': 'gbdt',\n",
    "                     'max_depth': -1,\n",
    "                     'objective': 'binary',\n",
    "                     'nthread': 3,\n",
    "                     'num_leaves': 6,\n",
    "                     'learning_rate': 0.1,\n",
    "                     'max_bin': 512,\n",
    "                     'subsample_for_bin': 200,\n",
    "                     'subsample': 1,\n",
    "                     'subsample_freq': 1,\n",
    "                     'colsample_bytree': 0.6,\n",
    "                     'reg_alpha': 0.5,\n",
    "                     'reg_lambda': 4,\n",
    "                     'min_split_gain': 0.5,\n",
    "                     'min_child_weight': 1,\n",
    "                     'min_child_samples': 5,\n",
    "                     'scale_pos_weight': 1,\n",
    "                     'num_class': 1,\n",
    "                     'metric': 'auc'}\n",
    "            \n",
    "            modellgb = lgb.train(params, d_train, 100)\n",
    "            y_predict_lgb[test] = modellgb.predict(X_test) \n",
    "\n",
    "        #============================================================================            \n",
    "        # XGB  \n",
    "        \n",
    "            xgtrain = xgb.DMatrix(X_train, y_train.values)\n",
    "            xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "            param = {'max_depth': 10, \n",
    "                     'min_child_weigth': 3, \n",
    "                     'eta': 0.02, \n",
    "                     'silent': 1,\n",
    "                     'eval_metric': 'auc',\n",
    "                     'seed': 1001,\n",
    "                     'colsample_bytree': 0.9,\n",
    "                     'subsample': 0.9,\n",
    "                     'gamma': 0.0964,\n",
    "                     'objective':'binary:logistic', \n",
    "                     'lambda': 2,\n",
    "                     'alpha': 0.03}\n",
    "            \n",
    "            num_round = 150\n",
    "            modelxgb = xgb.train(param, xgtrain, num_round)\n",
    "            y_predict_xgb[test] = modelxgb.predict(xgtest)\n",
    "            \n",
    "        #============================================================================\n",
    "        # LREG\n",
    "        \n",
    "            lm = linear_model.LinearRegression()\n",
    "            modelreg = lm.fit(X_train, y_train)\n",
    "            y_predict_reg[test]  = modelreg.predict(X_test)\n",
    "            \n",
    "        #============================================================================\n",
    "        \n",
    "    for i in range(0, len(y_predict_lgb)):\n",
    "        y_predict_lgb[i] = (y_predict_lgb[i] - y_predict_lgb.min()) / (y_predict_lgb.max() - y_predict_lgb.min())\n",
    "    \n",
    "    for i in range(0, len(y_predict_reg)):\n",
    "        y_predict_reg[i] = (y_predict_reg[i] - y_predict_reg.min()) / (y_predict_reg.max() - y_predict_reg.min())\n",
    "    \n",
    "    for i in range(0, len(y_predict_xgb)):\n",
    "        y_predict_xgb[i] = (y_predict_xgb[i] - y_predict_xgb.min()) / (y_predict_xgb.max() - y_predict_xgb.min()) \n",
    "        \n",
    "    #============================================================================\n",
    "    \n",
    "    return y_predict_lgb, y_predict_xgb, y_predict_reg, modelreg, modelxgb, modellgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df1.drop(columns = ['Survived'])\n",
    "y = df1['Survived']\n",
    "\n",
    "y_predict_lgb, y_predict_xgb, y_predict_reg, modelreg, modelxgb, modellgb = perform_repeated_cv(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 (Optional)\n",
    "\n",
    "We create ROC AUC curves to check how our trained models perform. Other metrics like accuracy_score can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# XGB\n",
    "\n",
    "actual = y\n",
    "predictions = y_predict_xgb\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(actual, predictions)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label = 'AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# LGBM\n",
    "\n",
    "actual = y \n",
    "predictions = y_predict_lgb\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(actual, predictions)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label = 'AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# REG\n",
    "\n",
    "actual = y \n",
    "predictions = y_predict_reg \n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(actual, predictions)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label = 'AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "We create predictions using our trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = df2.drop(columns = ['PassengerId'])\n",
    "yt = df2['PassengerId']\n",
    "\n",
    "sc = StandardScaler()\n",
    "Xt_test = sc.fit_transform(Xt)\n",
    "xgt_test = xgb.DMatrix(Xt_test)\n",
    "\n",
    "yt_predict_reg = modelreg.predict(Xt_test) # reg\n",
    "\n",
    "yt_predict_xgb = modelxgb.predict(xgt_test) # xgb \n",
    "\n",
    "yt_predict_lgb = modellgb.predict(Xt_test) #lgbm \n",
    "\n",
    "for i in range(0, len(yt_predict_lgb)):\n",
    "    yt_predict_lgb[i] = (yt_predict_lgb[i] - yt_predict_lgb.min()) / (yt_predict_lgb.max() - yt_predict_lgb.min())\n",
    "    \n",
    "for i in range(0, len(yt_predict_reg)):\n",
    "    yt_predict_reg[i] = (yt_predict_reg[i] - yt_predict_reg.min()) / (yt_predict_reg.max() - yt_predict_reg.min())\n",
    "    \n",
    "for i in range(0, len(yt_predict_xgb)):\n",
    "    yt_predict_xgb[i] = (yt_predict_xgb[i] - yt_predict_xgb.min()) / (yt_predict_xgb.max() - yt_predict_xgb.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "\n",
    "We add predicted scores to the DataFrames used for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_features = pd.DataFrame({'M_lgbm': y_predict_lgb, 'M_xgb': y_predict_xgb, 'M_reg': y_predict_reg})\n",
    "Mt_features = pd.DataFrame({'Mt_lgbm': yt_predict_lgb, 'Mt_xgb': yt_predict_xgb, 'Mt_reg': yt_predict_reg})\n",
    "\n",
    "df1 = df1.assign(M_lgbm = pd.Series(M_features['M_lgbm']), M_xgb = pd.Series(M_features['M_xgb']), M_reg = pd.Series(M_features['M_reg']))\n",
    "df2 = df2.assign(Mt_lgbm = pd.Series(Mt_features['Mt_lgbm']), Mt_xgb = pd.Series(Mt_features['Mt_xgb']), Mt_reg = pd.Series(Mt_features['Mt_reg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "\n",
    "We repeat previous steps, but this time we are using the Random Forest Classifier with our updated training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_repeated_cv_with_M_features(X, y):\n",
    "    #set the number of repetitions\n",
    "    n_reps = 50\n",
    "\n",
    "    for u in range(n_reps):\n",
    "        #initialize vector to keep predictions from all folds of the cross-validation\n",
    "        y_predict_rf = np.zeros(y.shape)\n",
    "\n",
    "        #perform 10-fold cross validation\n",
    "        skf = StratifiedKFold(n_splits = 5, random_state = 142)\n",
    "\n",
    "        for train, test in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "            y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "            #standardization\n",
    "            sc = StandardScaler().fit(X_train)\n",
    "            X_train = sc.transform(X_train)\n",
    "            X_test = sc.transform(X_test)\n",
    "            \n",
    "        #============================================================================\n",
    "        # RF\n",
    "            rf = RandomForestRegressor(n_estimators = 147, \n",
    "                           max_features = 0.1171,\n",
    "                           max_depth = 9, \n",
    "                           min_samples_split = 12,\n",
    "                           min_samples_leaf = 8,\n",
    "                           bootstrap = True,\n",
    "                           max_leaf_nodes = 25,\n",
    "                           min_weight_fraction_leaf = 0.2,\n",
    "                           random_state = 250) \n",
    "\n",
    "            modelrf = rf.fit(X_train, y_train)\n",
    "            y_predict_rf[test] = modelrf.predict(X_test)\n",
    "            \n",
    "        #============================================================================\n",
    "        \n",
    "#     for i in range(0, len(y_predict_rf)):\n",
    "#         y_predict_rf[i] = (y_predict_rf[i] - y_predict_rf.min()) / (y_predict_rf.max() - y_predict_rf.min())\n",
    "        \n",
    "    return y_predict_rf, modelrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xrf = df1.drop(columns = ['Survived'])\n",
    "yrf = df1['Survived']\n",
    "\n",
    "y_predict_rf, modelrf = perform_repeated_cv_with_M_features(Xrf, yrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = yrf \n",
    "predictions = y_predict_rf \n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(actual, predictions)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label = 'AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtrf = df2.drop(columns = ['PassengerId']) \n",
    "ytrf = df2['PassengerId']\n",
    "\n",
    "ytrf = ytrf.reset_index(drop=True)\n",
    "ytrf = pd.DataFrame(np.array(ytrf).reshape(len(ytrf)), columns = ['PassengerId'])\n",
    "\n",
    "Xtrf = pd.DataFrame(Xtrf)\n",
    "yt_predict_rf = modelrf.predict(Xtrf)\n",
    "\n",
    "# for i in range(0, len(yt_predict_rf)):\n",
    "#     yt_predict_rf[i] = (yt_predict_rf[i] - yt_predict_rf.min()) / (yt_predict_rf.max() - yt_predict_rf.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred_rf = pd.DataFrame({'SurvivalPred': yt_predict_rf})\n",
    "df_pred_rf['SurvivalPred'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "\n",
    "Scatter plots help us to determine the probabilty treshold to turn our probabilities into 0 and 1 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_pred_rf, df_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ytrf = ytrf.assign(Survived = pd.Series())\n",
    "\n",
    "for i in range(0, 418):\n",
    "    \n",
    "    if(df_pred_rf['SurvivalPred'][i] > 0.46):\n",
    "        ytrf['Survived'][i] = 1\n",
    "    if(df_pred_rf['SurvivalPred'][i] <= 0.46):\n",
    "        ytrf['Survived'][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 (Optional)\n",
    "\n",
    "After I have submitted a csv file to kaggle with only 0 values, my submissions scored 0.62679. I use the cell below to check how many 0 values I have in my submission file. If the cell outputs a value not in the 60-70% range, I can tell that something is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deathavgrf = (1 - sum(ytrf['Survived']) / 418) * 100\n",
    "\n",
    "print('[STACKING-rf]: ', deathavgrf, '% of passengers found dead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9\n",
    "\n",
    "Let's just save the file and submit it to kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrf['Survived'] = ytrf['Survived'].astype(int)\n",
    "ytrf.to_csv('score-stack-rf-079425.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
